<!DOCTYPE html><html lang="en-us" class="__variable_dd5b2f scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/36966cca54120369-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!6Tkw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae251e32-f6b4-4f95-86ea-09c333f5a809_1164x661.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!ifw1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe57e5977-fcd0-4725-92fe-05729ef07e92_833x500.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!5uVv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a796af3-d2d8-4358-b609-ce7bcf74abd9_480x720.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!q6nj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3504ccfd-7153-4ee0-8f53-0afe9115549f_786x396.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!s4dL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03b53518-2a8f-453b-95c7-c88a7dce5831_779x230.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!uF2P!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4faa600-35d5-4805-ad20-70df6cc64735_1600x590.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!nuHy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24eef740-991f-4e57-b9bd-3459891227d0_1600x662.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!gTbB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c82e7ae-9663-4a0e-a3fb-1438207d918d_1600x412.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!9r5e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265b0175-4ed9-4f93-a941-5b46e991da10_1600x402.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!WajD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930058ba-98a5-49d0-9962-1abc4ca9e3c5_800x396.png"/><link rel="stylesheet" href="/_next/static/css/c890694439b2475b.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1ea5cf861ee12a80.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/a9b9096fa657c0d0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-8506c16620cf39fb.js"/><script src="/_next/static/chunks/fd9d1056-30760135124e6678.js" async=""></script><script src="/_next/static/chunks/23-44b8024386371b46.js" async=""></script><script src="/_next/static/chunks/main-app-06a10a1bb45617e8.js" async=""></script><script src="/_next/static/chunks/ebde5ed1-51545511fe0d5050.js" async=""></script><script src="/_next/static/chunks/231-34a6a67d2da26855.js" async=""></script><script src="/_next/static/chunks/827-69594f61c16b8a9c.js" async=""></script><script src="/_next/static/chunks/850-ecf153581cc02044.js" async=""></script><script src="/_next/static/chunks/app/layout-54bebb918ae7f176.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-bd056182432da53b.js" async=""></script><script src="https://us.umami.is/script.js" async=""></script><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!VsZy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ec7709-933b-4304-b57b-7fcd1962637d_1600x1007.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!ITIG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d6dc18-85df-4d66-9c87-4ab246048464_2264x1290.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!9dMC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5ea7fed-3ee1-47e0-b59c-bba369c86a78_1846x1750.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!Ax4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feff05bd8-b3c9-48c1-b00f-054f6e16a7b0_1336x1496.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!SE5R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a3b38ac-9513-4c4a-92c0-e8c8f26d5865_660x440.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!c9W3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaf353e5-204b-4d51-b09a-ed8bdf2889fa_850x437.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!lhOI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4548e3b-e518-4a5e-bbc2-cccf1c7d1db6_2580x1530.png"/><link rel="preload" as="image" href="https://substackcdn.com/image/fetch/$s_!H_OC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6841c1fa-0603-4714-b4f7-b674960270b3_1386x1600.png"/><title>GPU网络通信基础</title><meta name="description" content="深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://blog.mainjay.cloudns.ch/blog/ai/gpu-networking-basics"/><link rel="alternate" type="application/rss+xml" href="https://blog.mainjay.cloudns.ch/feed.xml"/><meta property="og:title" content="GPU网络通信基础"/><meta property="og:description" content="深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。"/><meta property="og:url" content="https://blog.mainjay.cloudns.ch/blog/ai/gpu-networking-basics"/><meta property="og:site_name" content="MainJayLai Blog"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://pngimg.com/uploads/github/github_PNG80.png"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-09-05T00:00:00.000Z"/><meta property="article:modified_time" content="2025-09-05T00:00:00.000Z"/><meta property="article:author" content="mainJayLai"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="GPU网络通信基础"/><meta name="twitter:description" content="深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。"/><meta name="twitter:image" content="https://pngimg.com/uploads/github/github_PNG80.png"/><meta name="next-size-adjust"/><link rel="icon" type="image/png" href="https://mainjaylai.github.io/favicon.png"/><link rel="manifest" href="/static/favicons/manifest.json"/><meta name="msapplication-TileColor" content="#000000"/><meta name="theme-color" media="(prefers-color-scheme: light)" content="#fff"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000"/><meta name="referrer" content="no-referrer"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900&amp;display=swap" rel="stylesheet"/><link href="https://fonts.googleapis.com/css2?family=ZCOOL+KuaiLe&amp;family=ZCOOL+QingKe+HuangYou&amp;family=ZCOOL+XiaoWei&amp;display=swap" rel="stylesheet"/><script src="https://cdn.jsdelivr.net/gh/ashishagarwal2023/freegptjs@1.0.2/src/freegpt.min.js"></script><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="bg-white pl-[calc(100vw-100%)] text-black antialiased dark:bg-gray-950 dark:text-white"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('light')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'light'}catch(e){}}()</script><section class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex h-screen flex-col justify-between font-sans"><header class="flex items-center justify-between py-5"><div><a aria-label="Blog" href="/"><div class="flex items-center justify-between"><div class="mr-3"><img alt="logo" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" style="color:transparent" src="https://mainjaylai.github.io/favicon.png"/></div><div class="hidden h-[44px] text-center text-3xl font-semibold leading-10 sm:block">Blog</div></div></a></div><div class="flex items-center space-x-4 leading-5 sm:space-x-6"><a class="navbar-item hidden font-medium text-gray-900 dark:text-gray-100 sm:block" href="/blog">Blog</a><a class="navbar-item hidden font-medium text-gray-900 dark:text-gray-100 sm:block" href="/tags">Tags</a><a target="_blank" rel="noopener noreferrer" href="https://mainjaylai.github.io" class="navbar-item hidden font-medium text-gray-900 dark:text-gray-100 sm:block">About</a><button aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="h-6 w-6 text-gray-900 dark:text-gray-100"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg></button><div class="mr-8"><div class="relative inline-block text-left" data-headlessui-state=""><div><button id="headlessui-menu-button-:R5pkqja:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="h-6 w-6 text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" clip-rule="evenodd"></path></svg></button></div></div></div><button aria-label="AI Chat" class="flex items-center justify-center rounded-full p-1.5 text-gray-800 transition-all hover:bg-gray-100 dark:text-gray-200 dark:hover:bg-gray-800"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path><path d="M8 9h8"></path><path d="M8 13h6"></path></svg></button><div class="mr-5"><div class="relative inline-block text-left" data-headlessui-state=""><div><button class="flex items-center" id="headlessui-menu-button-:R6pkqja:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><div class="mr-2">简体中文</div><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1616" width="15" height="15"><path d="M670.72 325.696L511.552 152l87.68-87.872 360.96 389.504L832 453.76v0.64H64V325.76h606.72z m-318.4 382.08l157.248 172.8-94.976 79.552L63.872 579.84l147.712-0.704v-0.128H960v128.768H352.32z" fill="#262626" p-id="1617"></path></svg></button></div></div></div><button aria-label="Toggle Menu" class="sm:hidden"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="h-8 w-8 text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="opacity-98 fixed left-0 top-0 z-10 h-full w-full transform bg-white duration-300 ease-in-out dark:bg-gray-950 dark:opacity-[0.98] translate-x-full"><div class="flex justify-end"><button class="mr-8 mt-8 h-8 w-8" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><nav class="fixed mt-8 h-full"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 opacity-80 dark:text-gray-100" href="/">Home</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 opacity-80 dark:text-gray-100" href="/blog">Blog</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 opacity-80 dark:text-gray-100" href="/tags">Tags</a></div><div class="px-12 py-4"><a target="_blank" rel="noopener noreferrer" href="https://mainjaylai.github.io" class="text-2xl font-bold tracking-widest text-gray-900 opacity-80 dark:text-gray-100">About</a></div></nav></div></div></header><main class="mb-auto"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"GPU网络通信基础","datePublished":"2025-09-05T00:00:00.000Z","dateModified":"2025-09-05T00:00:00.000Z","description":"深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。","image":"https://pngimg.com/uploads/github/github_PNG80.png","url":"https://blog.mainjay.cloudns.ch/blog/ai/gpu-networking-basics","author":[{"@type":"Person","name":"mainJayLai"}]}</script><section class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="fixed bottom-8 right-8 hidden flex-col gap-3 md:hidden"><button aria-label="Scroll To Comment" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M18 10c0 3.866-3.582 7-8 7a8.841 8.841 0 01-4.083-.98L2 17l1.338-3.123C2.493 12.767 2 11.434 2 10c0-3.866 3.582-7 8-7s8 3.134 8 7zM7 9H5v2h2V9zm8 0h-2v2h2V9zM9 9h2v2H9V9z" clip-rule="evenodd"></path></svg></button><button aria-label="Scroll To Top" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z" clip-rule="evenodd"></path></svg></button></div><article><div><header><div class="space-y-1 border-b border-gray-200 pb-10 text-center dark:border-gray-700"><div class="beautiful-chinese-title"><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">GPU网络通信基础</h1></div><dl><div><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2025-09-05T00:00:00.000Z">September 5, 2025</time></dd></div></dl></div></header><div class="grid-rows-[auto_1fr] divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:divide-y-0"><div class="divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0"><div class="beautiful-chinese-content prose max-w-none pb-8 pt-10 dark:prose-invert"><h2 class="content-header" id="目录"><a href="#目录" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a>目录</h2><ul class=""><li class=""><a href="#背景动机">背景动机</a></li><li class=""><a href="#网络交换机">网络交换机</a></li><li class=""><a href="#横向扩展scale-out">横向扩展(Scale Out)</a></li><li class=""><a href="#纵向扩展scale-up">纵向扩展(Scale Up)</a></li><li class=""><a href="#训练过程中的通信">训练过程中的通信</a></li><li class=""><a href="#结论">结论</a></li></ul><h2 class="content-header" id="背景动机"><a href="#背景动机" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a>背景动机</h2><p>训练大型语言模型(LLM)需要大量的浮点运算(FLOPs)：</p><p><img alt="LLM训练需要的浮点运算量" src="https://substackcdn.com/image/fetch/$s_!6Tkw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae251e32-f6b4-4f95-86ea-09c333f5a809_1164x661.png"/></p><p>训练这些模型需要多长时间？</p><p>如果单个GPU每秒能执行约2 PetaFLOP（2 * 10^15浮点运算），一天有86,400秒，那么大约能达到1.7 x 10^20 FLOPS。在最理想的情况下，使用单个GPU，要达到10^24 FLOPs，你将需要约16年的训练时间。</p><p><strong>16年！没人有这么多时间！</strong></p><p>我们如何才能在数月甚至数周内训练出LLM？我们需要<em>大量</em>GPU同时工作。</p><p>这些GPU还需要相互通信，共享它们协同工作时的进度和结果。这种通信如何实现？<strong>网络通信！</strong></p><p><img alt="不是这种网络通信" src="https://substackcdn.com/image/fetch/$s_!ifw1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe57e5977-fcd0-4725-92fe-05729ef07e92_833x500.png"/></p><p>不，不是这种社交网络。</p><p><img alt="是这种网络通信" src="https://substackcdn.com/image/fetch/$s_!5uVv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a796af3-d2d8-4358-b609-ce7bcf74abd9_480x720.png"/></p><p>是的，就是这种计算机网络！😅</p><p>连接GPU实际上是一个相当有趣的问题。想象一下xAI需要协调20万个GPU之间的通信！</p><h2 class="content-header" id="网络交换机"><a href="#网络交换机" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a><strong>网络交换机</strong></h2><p>以xAI的20万GPU集群为例，如何连接它们？</p><p>在理想情况下，每个GPU都能以最快的速度与其他所有GPU通信。</p><p>首先想到的方案是：直接连接每个GPU和其他所有GPU。</p><p>不需要通过交换机或其他设备中转，因此通信应该非常快！</p><p><strong>这被称为&quot;全网状网络&quot;(full mesh network)。</strong></p><p>但在大规模场景下，全网状网络存在很多实际问题。</p><p>例如，要直接连接GPU对，每个GPU需要199,999个端口，我们总共需要约200亿条线缆！这显然不可行。</p><p>如果我们引入网络交换机呢？网络交换机是一种专用硬件，可以高效地在多个设备（在这种情况下是GPU）之间路由数据。</p><p>与其让每个GPU直接连接到其他所有GPU，我们可以将GPU连接到交换机，由交换机管理它们之间的通信。</p><p><img alt="网络交换机连接GPU" src="https://substackcdn.com/image/fetch/$s_!q6nj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3504ccfd-7153-4ee0-8f53-0afe9115549f_786x396.png"/> <em>网络交换机连接这些GPU，使它们能够相互通信</em></p><p>对于20万个GPU的集群，使用单个网络交换机将每个GPU的连线简化为一条，从200亿条线缆减少到仅20万条！</p><p>但这样的交换机仍需要20万个端口，这在实际上也不可行。</p><p><img alt="交换机示例" src="https://substackcdn.com/image/fetch/$s_!s4dL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03b53518-2a8f-453b-95c7-c88a7dce5831_779x230.png"/> <em>这种交换机需要放大8000倍才够用 😂</em></p><p>显然，一个巨型交换机无法解决问题，因此我们需要分层交换架构。</p><h3 class="content-header" id="叶脊拓扑结构"><a href="#叶脊拓扑结构" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a><strong>叶脊拓扑结构</strong></h3><p>与其使用一个巨大的交换机连接所有GPU，我们可以将网络组织成交换机的<em>层次结构</em>：</p><p><img alt="分层交换架构" src="https://substackcdn.com/image/fetch/$s_!uF2P!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4faa600-35d5-4805-ad20-70df6cc64735_1600x590.png"/></p><p>这种层次结构中的每个交换机可以更小，只连接一部分GPU，使其在尺寸和成本上更加可管理。</p><p>通过这种解决方案，GPU不再需要成千上万的直接连接，交换机也是如此！</p><p>然而，代价是当不同分支上的GPU需要通信时，数据必须通过多个交换机，引入额外的延迟。</p><p>举例说明，考虑两个没有连接到同一交换机的GPU。它们之间不再有直接连接，通信必须先到达高级交换机，再下行到目标GPU的交换机。</p><p><img alt="网络跳转增加延迟" src="https://substackcdn.com/image/fetch/$s_!nuHy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24eef740-991f-4e57-b9bd-3459891227d0_1600x662.png"/> <em>网络跳转增加了数据传输的时间</em></p><p>这种两层架构通常被称为<strong>叶脊架构</strong>或<strong>两层Clos网络</strong>。</p><p>叶交换机直接连接计算节点，脊交换机连接叶交换机：</p><p><img alt="叶脊拓扑架构" src="https://substackcdn.com/image/fetch/$s_!gTbB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c82e7ae-9663-4a0e-a3fb-1438207d918d_1600x412.png"/></p><h2 class="content-header" id="横向扩展scale-out"><a href="#横向扩展scale-out" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a>横向扩展(Scale Out)</h2><p>如何实现数千GPU的规模？</p><p><strong>横向扩展</strong>或<strong>水平扩展</strong>是通过添加更多GPU和网络交换机来扩展集群的方法。这有助于跨更多硬件分配训练工作负载，从而减少训练LLM所需的时间。</p><p><img alt="横向扩展" src="https://substackcdn.com/image/fetch/$s_!9r5e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265b0175-4ed9-4f93-a941-5b46e991da10_1600x402.png"/> <em>只需复制并粘贴网络架构...实现横向扩展！</em></p><p>这些GPU和交换机如何通信？横向扩展使用<strong>以太网</strong>或<strong>InfiniBand</strong>，这两种技术都能提供GPU间通信所需的高速网络连接。</p><p><strong>InfiniBand</strong>是英伟达的专有技术（通过收购Mellanox获得），由于其相比高性能以太网变体（如RoCE，即融合以太网上的RDMA）具有更低的延迟和更高的带宽，在大规模AI集群中历来更受青睐。</p><p><img alt="InfiniBand线缆" src="https://substackcdn.com/image/fetch/$s_!WajD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930058ba-98a5-49d0-9962-1abc4ca9e3c5_800x396.png"/> <em>如果你说这不是以太网线缆，你是对的！这是适用于Quantum-2交换机的1.5米(5英尺) NVIDIA/Mellanox MCP4Y10-N01A兼容800G OSFP顶部散热InfiniBand NDR无源直连铜缆</em></p><p>以太网在新的训练集群中越来越受欢迎。正如Jensen在本周英伟达GTC主题演讲中分享的，Elon的xAI使用英伟达的Spectrum X以太网构建了最大的训练集群(Colossus)。</p><h2 class="content-header" id="纵向扩展scale-up"><a href="#纵向扩展scale-up" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a>纵向扩展(Scale Up)</h2><p>横向扩展运行一段时间后，物理和经济因素开始限制其发展。更多设备和交换机意味着额外的跳转延迟、更高的功耗和成本上升。在某个点上，单纯的横向扩展不再是最佳解决方案。</p><p>这引出了另一种方法：<strong>纵向扩展</strong>或<strong>垂直扩展</strong>。</p><p>纵向扩展意味着增加每个节点的计算能力，而不是增加更多节点。</p><p>每个叶交换机不直接连接到单个GPU，而是连接到包含多个GPU（比如每台服务器8个）的服务器。这减少了所需的直接网络交换机和线缆数量：</p><p><img alt="服务器节点内的8个GPU" src="https://substackcdn.com/image/fetch/$s_!VsZy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ec7709-933b-4304-b57b-7fcd1962637d_1600x1007.png"/> <em>每个服务器节点包含8个GPU；单个交换机可以管理更多GPU</em></p><p>打个比方，在网络扩展的早期阶段，快速增长的公司可能首先通过增加CPU核心和内存来升级服务器。这是垂直扩展。当单个机器不够用时，他们会添加更多服务器和负载均衡器来分配流量。这是水平扩展。</p><p>细心的观察者可能会想知道这些纵向扩展的GPU如何相互通信。<em>它们不是仍然需要通过网络交换机连接吗？如果是，这与横向扩展有何不同？</em></p><p>非常好的观察！</p><h3 class="content-header" id="节点内通信与节点间通信"><a href="#节点内通信与节点间通信" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a><strong>节点内通信与节点间通信</strong></h3><p>服务器节点内的通信称为<strong>节点内(intra-node)通信</strong>。</p><p><img alt="节点内通信" src="https://substackcdn.com/image/fetch/$s_!ITIG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d6dc18-85df-4d66-9c87-4ab246048464_2264x1290.png"/></p><p>不同服务器节点上GPU之间的通信称为<strong>节点间(inter-node)通信</strong>。</p><p><img alt="节点间通信" src="https://substackcdn.com/image/fetch/$s_!9dMC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5ea7fed-3ee1-47e0-b59c-bba369c86a78_1846x1750.png"/></p><p>事实证明，相邻节点内的GPU可以比使用节点间InfiniBand或以太网技术更快、更高带宽地通信。</p><p>为什么？</p><p>这主要是由于GPU的物理接近性和采用的专用互连技术。这些技术使用直接、短距离且优化的信号线路，通常直接集成在同一电路板上或共享封装内。这减少了信号传输距离并最小化了延迟。</p><p>例如，这是2018年IEEE国际固态电路会议(ISSCC)论文集中分享的AMD Infinity Fabric路由示意图：</p><p><img alt="AMD Infinity Fabric路由" src="https://substackcdn.com/image/fetch/$s_!Ax4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feff05bd8-b3c9-48c1-b00f-054f6e16a7b0_1336x1496.png"/> <em>亮色连接线(traces)代表计算单元之间的金属连接。可以将其视为封装基板中的&quot;线路&quot;。</em></p><p>由于服务器内的GPU直接连接，它们可以避免节点间GPU服务器通信相关的大部分开销。封装内路由通过保持短线距、减少传播延迟和最小化信号衰减来提高效率。</p><p>InfiniBand和以太网等外部连接通常需要额外的信号完整性组件——如中继器、重定时器和纠错机制——以保持较长距离的可靠传输。这些可能会引入增量延迟并增加功耗。</p><p>我喜欢将节点内通信（如NVLink和InfinityFabric）比作德国高速公路(Autobahn)：设计为无中断高速行驶。</p><p><strong>节点间通信则像双车道公路</strong>：速度较慢，容量有限，而且在春季播种或秋季收获期间可能需要减速绕过拖拉机（即处理拥堵）。</p><p><img alt="小心前方可能有警车" src="https://substackcdn.com/image/fetch/$s_!SE5R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a3b38ac-9513-4c4a-92c0-e8c8f26d5865_660x440.png"/> <em>小心，前面可能有警车！</em></p><h2 class="content-header" id="训练过程中的通信"><a href="#训练过程中的通信" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a><strong>训练过程中的通信</strong></h2><p>了解神经网络的训练方式有助于理解通信挑战。</p><p>在每个训练周期中，网络首先执行<strong>前向传播</strong>，输入数据流经网络各层产生预测结果。然后通过损失函数将这一预测与正确答案进行比较，量化预测的偏差程度。</p><p>学习的核心发生在<strong>反向传播</strong>过程中，一种叫做反向传播的算法计算网络中每个权重对误差的贡献程度。利用这些信息，梯度下降算法调整所有权重朝着减少误差的方向——本质上是调整数十亿个&quot;旋钮&quot;，逐步提高网络的准确性。通过每次迭代，这些渐进式调整使神经网络能够在新数据上做出更可靠的预测。</p><p><img alt="前向传播过程" src="https://substackcdn.com/image/fetch/$s_!c9W3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaf353e5-204b-4d51-b09a-ed8bdf2889fa_850x437.png"/> <em>神经网络前向传播过程</em></p><p>每个GPU基于前向传播的误差计算权重更新的梯度，但由于每个GPU在不同的数据子集上工作，这些梯度只是部分结果。为确保所有GPU应用相同的更新并保持同步，<strong>需要在GPU间聚合和平均梯度</strong>。</p><p>这个过程，被称为<strong>all-reduce通信</strong>，允许GPU交换和分发最终计算值，然后更新它们的本地模型。通过维持全局一致性，这防止了模型偏移并确保有效的分布式训练。</p><p>all-reduce通信的延迟直接影响训练效率。</p><p>英伟达的NCCL软件库还支持其他集体操作，例如：AllReduce、Broadcast、Reduce、AllGather和ReduceScatter。</p><p>正如我们在DeepSeek V3中看到的，有软件方法可以重叠通信和计算，减少GPU空闲时间，降低通信约束的影响。</p><h2 class="content-header" id="结论"><a href="#结论" aria-hidden="true" tabindex="-1"><span class="content-header-link"><svg class="h-5 linkicon w-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"></path><path d="M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"></path></svg></span></a><strong>结论</strong></h2><p>这是第一部分的全部内容。正如承诺的，内容非常温和！</p><p>还有很多内容需要讨论。实际的大规模集群并不是全网状的；情况更复杂。</p><p><img alt="复杂集群拓扑" src="https://substackcdn.com/image/fetch/$s_!lhOI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4548e3b-e518-4a5e-bbc2-cccf1c7d1db6_2580x1530.png"/></p><p>但希望你已经掌握了足够的知识，当看到图表和文档时，例如这张英伟达SuperPOD计算架构图，能够获得高层次的理解并提出问题以填补知识空白：</p><p><img alt="英伟达SuperPOD架构" src="https://substackcdn.com/image/fetch/$s_!H_OC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6841c1fa-0603-4714-b4f7-b674960270b3_1386x1600.png"/></p><p>在上图中，我们可以看到脊交换机和叶交换机如何帮助横向扩展，以及B200服务器如何实现纵向扩展。</p><p>从表格中可以看出，每个可扩展单元(SU)有32个节点，每个节点有8个GPU。所以这是横向扩展（32个节点）和纵向扩展（每节点8个GPU）的结合。忽略&quot;移除一个DGX以容纳UFM连接&quot;的细节；重点是你现在可以大致理解这些内容了！</p></div></div><div class="pb-6 pt-6 text-center text-gray-700 dark:text-gray-300" id="comment"></div><footer><div class="flex flex-col text-sm font-medium sm:flex-row sm:justify-between sm:text-base"><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" aria-label="Previous post: 深入理解 Go 的内存对齐与分配机制" href="/blog/go/go-memory-alignment-and-allocation">← <!-- -->深入理解 Go 的内存对齐与分配机制</a></div><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" aria-label="Next post: 使用公平队列防止多租户服务中的吵闹邻居问题" href="/blog/system/fair-queueing">使用公平队列防止多租户服务中的吵闹邻居问题<!-- --> →</a></div></div></footer></div></div></article></section></main><footer><div class="mt-16 flex flex-col items-center"><div class="mb-3 flex space-x-4"><a class="text-sm !text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:mainjaylai@outlook.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6"><path d="M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"></path><path d="M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"></path></svg></a><a class="text-sm !text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/mainjaylai"><span class="sr-only">github</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm !text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://gitlab.com/JayMain"><span class="sr-only">gitlab</span><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6" width="200" height="200"><path d="M1022.08 579.712l-57.258667-176.426667-113.664-349.397333a19.413333 19.413333 0 0 0-36.992 0L700.501333 403.2H323.498667L209.877333 53.888C204.074667 35.84 178.56 35.84 172.8 53.76L59.136 403.157333 1.877333 579.712a39.424 39.424 0 0 0 14.122667 43.648L512 983.637333l496-360.234666a39.253333 39.253333 0 0 0 14.08-43.690667"></path></svg></a><a class="text-sm !text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://gitee.com/lmj2001"><span class="sr-only">gitee</span><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6" width="200" height="200"><path d="M512 992C246.895625 992 32 777.104375 32 512S246.895625 32 512 32s480 214.895625 480 480-214.895625 480-480 480z m242.9521875-533.3278125h-272.56875a23.7121875 23.7121875 0 0 0-23.71125 23.7121875l-0.024375 59.255625c0 13.08 10.6078125 23.7121875 23.6878125 23.7121875h165.96c13.104375 0 23.7121875 10.6078125 23.7121875 23.6878125v11.855625a71.1121875 71.1121875 0 0 1-71.1121875 71.1121875h-225.215625a23.7121875 23.7121875 0 0 1-23.6878125-23.7121875V423.1278125a71.1121875 71.1121875 0 0 1 71.0878125-71.1121875h331.824375a23.7121875 23.7121875 0 0 0 23.6878125-23.71125l0.0721875-59.2565625a23.7121875 23.7121875 0 0 0-23.68875-23.7121875H423.08a177.76875 177.76875 0 0 0-177.76875 177.7921875V754.953125c0 13.1034375 10.60875 23.7121875 23.713125 23.7121875h349.63125a159.984375 159.984375 0 0 0 159.984375-159.984375V482.36a23.7121875 23.7121875 0 0 0-23.7121875-23.6878125z"></path></svg></a></div><div class="mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>MainJayLai</div><div> • </div><div>© 2025</div><div> • </div><a href="/">MainJayLai Blog</a></div></div></footer></div></section><script src="/_next/static/chunks/webpack-8506c16620cf39fb.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/36966cca54120369-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/c890694439b2475b.css\",\"style\"]\n3:HL[\"/_next/static/css/1ea5cf861ee12a80.css\",\"style\"]\n4:HL[\"/_next/static/css/a9b9096fa657c0d0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[5751,[],\"\"]\n8:I[9275,[],\"\"]\na:I[1343,[],\"\"]\nb:I[8700,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"ThemeProviders\"]\nc:I[4080,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"\"]\nd:I[9032,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"KBarSearchProvider\"]\ne:I[231,[\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"797\",\"static/chunks/app/blog/%5B...slug%5D/page-bd056182432da53b.js\"],\"\"]\nf:I[8173,[\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"797\",\"static/chunks/app/blog/%5B...slug%5D/page-bd056182432da53b.js\"],\"Image\"]\n10:I[509,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"KBarButton\"]\n11:I[1398,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"default\"]\n12:I[7606,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"default\"]\n13:I[7510,[\"599\",\"static/chunks/ebde5ed1-5"])</script><script>self.__next_f.push([1,"1545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"default\"]\n14:I[8976,[\"599\",\"static/chunks/ebde5ed1-51545511fe0d5050.js\",\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"850\",\"static/chunks/850-ecf153581cc02044.js\",\"185\",\"static/chunks/app/layout-54bebb918ae7f176.js\"],\"default\"]\n16:I[6130,[],\"\"]\n9:[\"slug\",\"ai/gpu-networking-basics\",\"c\"]\n17:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c890694439b2475b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1ea5cf861ee12a80.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"Ts-6BBsjdSlBnGT_Ikyc2\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/blog/ai/gpu-networking-basics\",\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"ai/gpu-networking-basics\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"gpu-networking-basics\\\"]}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"ai/gpu-networking-basics\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$L7\"],null],null]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$9\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/a9b9096fa657c0d0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}],null]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en-us\",\"className\":\"__variable_dd5b2f scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"href\":\"https://mainjaylai.github.io/favicon.png\"}],[\"$\",\"link\",null,{\"rel\":\"manifest\",\"href\":\"/static/favicons/manifest.json\"}],[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#000000\"}],[\"$\",\"link\",null,{\"href\":\"https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@200..900\u0026display=swap\",\"rel\":\"stylesheet\"}],[\"$\",\"link\",null,{\"href\":\"https://fonts.googleapis.com/css2?family=ZCOOL+KuaiLe\u0026family=ZCOOL+QingKe+HuangYou\u0026family=ZCOOL+XiaoWei\u0026display=swap\",\"rel\":\"stylesheet\"}],[\"$\",\"script\",null,{\"src\":\"https://us.umami.is/script.js\",\"async\":true}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"media\":\"(prefers-color-scheme: light)\",\"content\":\"#fff\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"media\":\"(prefers-color-scheme: dark)\",\"content\":\"#000\"}],[\"$\",\"meta\",null,{\"name\":\"referrer\",\"content\":\"no-referrer\"}],[\"$\",\"script\",null,{\"src\":\"https://cdn.jsdelivr.net/gh/ashishagarwal2023/freegptjs@1.0.2/src/freegpt.min.js\"}],[\"$\",\"link\",null,{\"rel\":\"alternate\",\"type\":\"application/rss+xml\",\"href\":\"/feed.xml\"}]]}],[\"$\",\"body\",null,{\"className\":\"bg-white pl-[calc(100vw-100%)] text-black antialiased dark:bg-gray-950 dark:text-white\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[[\"$undefined\",\"$undefined\",\"$undefined\",[\"$\",\"$Lc\",null,{\"async\":true,\"defer\":true,\"data-website-id\":\"bbe21cb3-3de3-4ba7-b6de-453053bc6ae8\",\"src\":\"https://us.umami.is/script.js\"}],\"$undefined\",\"$undefined\"],[\"$\",\"section\",null,{\"className\":\"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex h-screen flex-col justify-between font-sans\",\"children\":[[\"$\",\"$Ld\",null,{\"kbarConfig\":{\"searchDocumentsPath\":\"/search.json\"},\"children\":[[\"$\",\"header\",null,{\"className\":\"flex items-center justify-between py-5\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"$Le\",null,{\"href\":\"/\",\"aria-label\":\"Blog\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-between\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mr-3\",\"children\":[\"$\",\"$Lf\",null,{\"src\":\"https://mainjaylai.github.io/favicon.png\",\"width\":44,\"height\":44,\"alt\":\"logo\"}]}],[\"$\",\"div\",null,{\"className\":\"hidden h-[44px] text-center text-3xl font-semibold leading-10 sm:block\",\"children\":\"Blog\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"flex items-center space-x-4 leading-5 sm:space-x-6\",\"children\":[[[\"$\",\"$Le\",null,{\"href\":\"/blog\",\"className\":\"navbar-item hidden font-medium text-gray-900 dark:text-gray-100 sm:block\",\"children\":\"Blog\"}],[\"$\",\"$Le\",null,{\"href\":\"/tags\",\"className\":\"navbar-item hidden font-medium text-gray-900 dark:text-gray-100 sm:block\",\"children\":\"Tags\"}],[\"$\",\"a\",null,{\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://mainjaylai.github.io\",\"className\":\"navbar-item hidden font-medium text-gray-900 dark:text-gray-100 sm:block\",\"children\":\"About\"}]],[\"$\",\"$L10\",null,{\"aria-label\":\"Search\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"fill\":\"none\",\"viewBox\":\"0 0 24 24\",\"strokeWidth\":1.5,\"stroke\":\"currentColor\",\"className\":\"h-6 w-6 text-gray-900 dark:text-gray-100\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"d\":\"M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z\"}]}]}],[\"$\",\"$L11\",null,{}],[\"$\",\"$L12\",null,{}],[\"$\",\"$L13\",null,{}],[\"$\",\"$L14\",null,{}]]}]]}],[\"$\",\"main\",null,{\"className\":\"mb-auto\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"space-x-2 pb-8 pt-6 md:space-y-5\",\"children\":[\"$\",\"h1\",null,{\"className\":\"text-6xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 md:border-r-2 md:px-6 md:text-8xl md:leading-14\",\"children\":\"404\"}]}],[\"$\",\"div\",null,{\"className\":\"max-w-md\",\"children\":[[\"$\",\"p\",null,{\"className\":\"mb-4 text-xl font-bold leading-normal md:text-2xl\",\"children\":\"Sorry we couldn't find this page.\"}],[\"$\",\"p\",null,{\"className\":\"mb-8\",\"children\":\"But dont worry, you can find plenty of other things on our homepage.\"}],[\"$\",\"$Le\",null,{\"href\":\"/\",\"className\":\"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm font-medium leading-5 text-white shadow transition-colors duration-150 hover:bg-blue-700 focus:outline-none dark:hover:bg-blue-500\",\"children\":\"Back to homepage\"}]]}]]}],\"notFoundStyles\":[],\"styles\":null}]}]]}],[\"$\",\"footer\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"mt-16 flex flex-col items-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 flex space-x-4\",\"children\":[[\"$\",\"a\",null,{\"className\":\"text-sm !text-gray-500 transition hover:text-gray-600\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"mailto:mainjaylai@outlook.com\",\"children\":[[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"mail\"}],[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 20 20\",\"className\":\"fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z\"}],[\"$\",\"path\",null,{\"d\":\"M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z\"}]]}]]}],[\"$\",\"a\",null,{\"className\":\"text-sm !text-gray-500 transition hover:text-gray-600\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://github.com/mainjaylai\",\"children\":[[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"github\"}],[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 24 24\",\"className\":\"fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6\",\"children\":[\"$\",\"path\",null,{\"d\":\"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12\"}]}]]}],[\"$\",\"a\",null,{\"className\":\"text-sm !text-gray-500 transition hover:text-gray-600\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://gitlab.com/JayMain\",\"children\":[[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"gitlab\"}],[\"$\",\"svg\",null,{\"viewBox\":\"0 0 1024 1024\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"className\":\"fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6\",\"width\":\"200\",\"height\":\"200\",\"children\":[\"$\",\"path\",null,{\"d\":\"M1022.08 579.712l-57.258667-176.426667-113.664-349.397333a19.413333 19.413333 0 0 0-36.992 0L700.501333 403.2H323.498667L209.877333 53.888C204.074667 35.84 178.56 35.84 172.8 53.76L59.136 403.157333 1.877333 579.712a39.424 39.424 0 0 0 14.122667 43.648L512 983.637333l496-360.234666a39.253333 39.253333 0 0 0 14.08-43.690667\"}]}]]}],[\"$\",\"a\",null,{\"className\":\"text-sm !text-gray-500 transition hover:text-gray-600\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://gitee.com/lmj2001\",\"children\":[[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"gitee\"}],[\"$\",\"svg\",null,{\"viewBox\":\"0 0 1024 1024\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"className\":\"fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 dark:hover:text-primary-400 h-6 w-6\",\"width\":\"200\",\"height\":\"200\",\"children\":[\"$\",\"path\",null,{\"d\":\"M512 992C246.895625 992 32 777.104375 32 512S246.895625 32 512 32s480 214.895625 480 480-214.895625 480-480 480z m242.9521875-533.3278125h-272.56875a23.7121875 23.7121875 0 0 0-23.71125 23.7121875l-0.024375 59.255625c0 13.08 10.6078125 23.7121875 23.6878125 23.7121875h165.96c13.104375 0 23.7121875 10.6078125 23.7121875 23.6878125v11.855625a71.1121875 71.1121875 0 0 1-71.1121875 71.1121875h-225.215625a23.7121875 23.7121875 0 0 1-23.6878125-23.7121875V423.1278125a71.1121875 71.1121875 0 0 1 71.0878125-71.1121875h331.824375a23.7121875 23.7121875 0 0 0 23.6878125-23.71125l0.0721875-59.2565625a23.7121875 23.7121875 0 0 0-23.68875-23.7121875H423.08a177.76875 177.76875 0 0 0-177.76875 177.7921875V754.953125c0 13.1034375 10.60875 23.7121875 23.713125 23.7121875h349.63125a159.984375 159.984375 0 0 0 159.984375-159.984375V482.36a23.7121875 23.7121875 0 0 0-23.7121875-23.6878125z\"}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400\",\"children\":[[\"$\",\"div\",null,{\"children\":\"MainJayLai\"}],[\"$\",\"div\",null,{\"children\":\" • \"}],[\"$\",\"div\",null,{\"children\":\"© 2025\"}],[\"$\",\"div\",null,{\"children\":\" • \"}],[\"$\",\"$Le\",null,{\"href\":\"/\",\"children\":\"MainJayLai Blog\"}]]}]]}]}]]}]}]]}]}]]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$L15\"],\"globalErrorComponent\":\"$16\",\"missingSlots\":\"$W17\"}]]\n"])</script><script>self.__next_f.push([1,"18:I[4347,[\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"797\",\"static/chunks/app/blog/%5B...slug%5D/page-bd056182432da53b.js\"],\"default\"]\n19:I[9629,[\"231\",\"static/chunks/231-34a6a67d2da26855.js\",\"827\",\"static/chunks/827-69594f61c16b8a9c.js\",\"797\",\"static/chunks/app/blog/%5B...slug%5D/page-bd056182432da53b.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"7:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BlogPosting\\\",\\\"headline\\\":\\\"GPU网络通信基础\\\",\\\"datePublished\\\":\\\"2025-09-05T00:00:00.000Z\\\",\\\"dateModified\\\":\\\"2025-09-05T00:00:00.000Z\\\",\\\"description\\\":\\\"深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。\\\",\\\"image\\\":\\\"https://pngimg.com/uploads/github/github_PNG80.png\\\",\\\"url\\\":\\\"https://blog.mainjay.cloudns.ch/blog/ai/gpu-networking-basics\\\",\\\"author\\\":[{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"mainJayLai\\\"}]}\"}}],[\"$\",\"section\",null,{\"className\":\"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0\",\"children\":[[\"$\",\"$L18\",null,{}],[\"$\",\"article\",null,{\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"header\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-1 border-b border-gray-200 pb-10 text-center dark:border-gray-700\",\"children\":[[\"$\",\"div\",null,{\"className\":\"beautiful-chinese-title\",\"children\":[\"$\",\"h1\",null,{\"className\":\"text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14\",\"children\":\"GPU网络通信基础\"}]}],[\"$\",\"dl\",null,{\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"dt\",null,{\"className\":\"sr-only\",\"children\":\"Published on\"}],[\"$\",\"dd\",null,{\"className\":\"text-base font-medium leading-6 text-gray-500 dark:text-gray-400\",\"children\":[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05T00:00:00.000Z\",\"children\":\"September 5, 2025\"}]}]]}]}]]}]}],[\"$\",\"div\",null,{\"className\":\"grid-rows-[auto_1fr] divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:divide-y-0\",\"children\":[[\"$\",\"div\",null,{\"className\":\"divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"beautiful-chinese-content prose max-w-none pb-8 pt-10 dark:prose-invert\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"目录\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#目录\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],\"目录\"]}],[\"$\",\"ul\",null,{\"className\":\"\",\"children\":[[\"$\",\"li\",\"0\",{\"className\":\"\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#背景动机\",\"children\":\"背景动机\"}],null]}],[\"$\",\"li\",\"1\",{\"className\":\"\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#网络交换机\",\"children\":\"网络交换机\"}],null]}],[\"$\",\"li\",\"2\",{\"className\":\"\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#横向扩展scale-out\",\"children\":\"横向扩展(Scale Out)\"}],null]}],[\"$\",\"li\",\"3\",{\"className\":\"\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#纵向扩展scale-up\",\"children\":\"纵向扩展(Scale Up)\"}],null]}],[\"$\",\"li\",\"4\",{\"className\":\"\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#训练过程中的通信\",\"children\":\"训练过程中的通信\"}],null]}],[\"$\",\"li\",\"5\",{\"className\":\"\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#结论\",\"children\":\"结论\"}],null]}]]}],[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"背景动机\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#背景动机\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],\"背景动机\"]}],[\"$\",\"p\",null,{\"children\":\"训练大型语言模型(LLM)需要大量的浮点运算(FLOPs)：\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"LLM训练需要的浮点运算量\",\"src\":\"https://substackcdn.com/image/fetch/$s_!6Tkw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae251e32-f6b4-4f95-86ea-09c333f5a809_1164x661.png\"}]}],[\"$\",\"p\",null,{\"children\":\"训练这些模型需要多长时间？\"}],[\"$\",\"p\",null,{\"children\":\"如果单个GPU每秒能执行约2 PetaFLOP（2 * 10^15浮点运算），一天有86,400秒，那么大约能达到1.7 x 10^20 FLOPS。在最理想的情况下，使用单个GPU，要达到10^24 FLOPs，你将需要约16年的训练时间。\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"16年！没人有这么多时间！\"}]}],[\"$\",\"p\",null,{\"children\":[\"我们如何才能在数月甚至数周内训练出LLM？我们需要\",[\"$\",\"em\",null,{\"children\":\"大量\"}],\"GPU同时工作。\"]}],[\"$\",\"p\",null,{\"children\":[\"这些GPU还需要相互通信，共享它们协同工作时的进度和结果。这种通信如何实现？\",[\"$\",\"strong\",null,{\"children\":\"网络通信！\"}]]}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"不是这种网络通信\",\"src\":\"https://substackcdn.com/image/fetch/$s_!ifw1!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe57e5977-fcd0-4725-92fe-05729ef07e92_833x500.png\"}]}],[\"$\",\"p\",null,{\"children\":\"不，不是这种社交网络。\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"是这种网络通信\",\"src\":\"https://substackcdn.com/image/fetch/$s_!5uVv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a796af3-d2d8-4358-b609-ce7bcf74abd9_480x720.png\"}]}],[\"$\",\"p\",null,{\"children\":\"是的，就是这种计算机网络！😅\"}],[\"$\",\"p\",null,{\"children\":\"连接GPU实际上是一个相当有趣的问题。想象一下xAI需要协调20万个GPU之间的通信！\"}],[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"网络交换机\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#网络交换机\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],[\"$\",\"strong\",null,{\"children\":\"网络交换机\"}]]}],[\"$\",\"p\",null,{\"children\":\"以xAI的20万GPU集群为例，如何连接它们？\"}],[\"$\",\"p\",null,{\"children\":\"在理想情况下，每个GPU都能以最快的速度与其他所有GPU通信。\"}],[\"$\",\"p\",null,{\"children\":\"首先想到的方案是：直接连接每个GPU和其他所有GPU。\"}],[\"$\",\"p\",null,{\"children\":\"不需要通过交换机或其他设备中转，因此通信应该非常快！\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"这被称为\\\"全网状网络\\\"(full mesh network)。\"}]}],[\"$\",\"p\",null,{\"children\":\"但在大规模场景下，全网状网络存在很多实际问题。\"}],[\"$\",\"p\",null,{\"children\":\"例如，要直接连接GPU对，每个GPU需要199,999个端口，我们总共需要约200亿条线缆！这显然不可行。\"}],[\"$\",\"p\",null,{\"children\":\"如果我们引入网络交换机呢？网络交换机是一种专用硬件，可以高效地在多个设备（在这种情况下是GPU）之间路由数据。\"}],[\"$\",\"p\",null,{\"children\":\"与其让每个GPU直接连接到其他所有GPU，我们可以将GPU连接到交换机，由交换机管理它们之间的通信。\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"网络交换机连接GPU\",\"src\":\"https://substackcdn.com/image/fetch/$s_!q6nj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3504ccfd-7153-4ee0-8f53-0afe9115549f_786x396.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"网络交换机连接这些GPU，使它们能够相互通信\"}]]}],[\"$\",\"p\",null,{\"children\":\"对于20万个GPU的集群，使用单个网络交换机将每个GPU的连线简化为一条，从200亿条线缆减少到仅20万条！\"}],[\"$\",\"p\",null,{\"children\":\"但这样的交换机仍需要20万个端口，这在实际上也不可行。\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"交换机示例\",\"src\":\"https://substackcdn.com/image/fetch/$s_!s4dL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03b53518-2a8f-453b-95c7-c88a7dce5831_779x230.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"这种交换机需要放大8000倍才够用 😂\"}]]}],[\"$\",\"p\",null,{\"children\":\"显然，一个巨型交换机无法解决问题，因此我们需要分层交换架构。\"}],[\"$\",\"h3\",null,{\"className\":\"content-header\",\"id\":\"叶脊拓扑结构\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#叶脊拓扑结构\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],[\"$\",\"strong\",null,{\"children\":\"叶脊拓扑结构\"}]]}],[\"$\",\"p\",null,{\"children\":[\"与其使用一个巨大的交换机连接所有GPU，我们可以将网络组织成交换机的\",[\"$\",\"em\",null,{\"children\":\"层次结构\"}],\"：\"]}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"分层交换架构\",\"src\":\"https://substackcdn.com/image/fetch/$s_!uF2P!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4faa600-35d5-4805-ad20-70df6cc64735_1600x590.png\"}]}],[\"$\",\"p\",null,{\"children\":\"这种层次结构中的每个交换机可以更小，只连接一部分GPU，使其在尺寸和成本上更加可管理。\"}],[\"$\",\"p\",null,{\"children\":\"通过这种解决方案，GPU不再需要成千上万的直接连接，交换机也是如此！\"}],[\"$\",\"p\",null,{\"children\":\"然而，代价是当不同分支上的GPU需要通信时，数据必须通过多个交换机，引入额外的延迟。\"}],[\"$\",\"p\",null,{\"children\":\"举例说明，考虑两个没有连接到同一交换机的GPU。它们之间不再有直接连接，通信必须先到达高级交换机，再下行到目标GPU的交换机。\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"网络跳转增加延迟\",\"src\":\"https://substackcdn.com/image/fetch/$s_!nuHy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24eef740-991f-4e57-b9bd-3459891227d0_1600x662.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"网络跳转增加了数据传输的时间\"}]]}],[\"$\",\"p\",null,{\"children\":[\"这种两层架构通常被称为\",[\"$\",\"strong\",null,{\"children\":\"叶脊架构\"}],\"或\",[\"$\",\"strong\",null,{\"children\":\"两层Clos网络\"}],\"。\"]}],[\"$\",\"p\",null,{\"children\":\"叶交换机直接连接计算节点，脊交换机连接叶交换机：\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"叶脊拓扑架构\",\"src\":\"https://substackcdn.com/image/fetch/$s_!gTbB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c82e7ae-9663-4a0e-a3fb-1438207d918d_1600x412.png\"}]}],[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"横向扩展scale-out\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#横向扩展scale-out\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],\"横向扩展(Scale Out)\"]}],[\"$\",\"p\",null,{\"children\":\"如何实现数千GPU的规模？\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"横向扩展\"}],\"或\",[\"$\",\"strong\",null,{\"children\":\"水平扩展\"}],\"是通过添加更多GPU和网络交换机来扩展集群的方法。这有助于跨更多硬件分配训练工作负载，从而减少训练LLM所需的时间。\"]}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"横向扩展\",\"src\":\"https://substackcdn.com/image/fetch/$s_!9r5e!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265b0175-4ed9-4f93-a941-5b46e991da10_1600x402.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"只需复制并粘贴网络架构...实现横向扩展！\"}]]}],[\"$\",\"p\",null,{\"children\":[\"这些GPU和交换机如何通信？横向扩展使用\",[\"$\",\"strong\",null,{\"children\":\"以太网\"}],\"或\",[\"$\",\"strong\",null,{\"children\":\"InfiniBand\"}],\"，这两种技术都能提供GPU间通信所需的高速网络连接。\"]}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"InfiniBand\"}],\"是英伟达的专有技术（通过收购Mellanox获得），由于其相比高性能以太网变体（如RoCE，即融合以太网上的RDMA）具有更低的延迟和更高的带宽，在大规模AI集群中历来更受青睐。\"]}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"InfiniBand线缆\",\"src\":\"https://substackcdn.com/image/fetch/$s_!WajD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F930058ba-98a5-49d0-9962-1abc4ca9e3c5_800x396.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"如果你说这不是以太网线缆，你是对的！这是适用于Quantum-2交换机的1.5米(5英尺) NVIDIA/Mellanox MCP4Y10-N01A兼容800G OSFP顶部散热InfiniBand NDR无源直连铜缆\"}]]}],[\"$\",\"p\",null,{\"children\":\"以太网在新的训练集群中越来越受欢迎。正如Jensen在本周英伟达GTC主题演讲中分享的，Elon的xAI使用英伟达的Spectrum X以太网构建了最大的训练集群(Colossus)。\"}],[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"纵向扩展scale-up\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#纵向扩展scale-up\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],\"纵向扩展(Scale Up)\"]}],[\"$\",\"p\",null,{\"children\":\"横向扩展运行一段时间后，物理和经济因素开始限制其发展。更多设备和交换机意味着额外的跳转延迟、更高的功耗和成本上升。在某个点上，单纯的横向扩展不再是最佳解决方案。\"}],[\"$\",\"p\",null,{\"children\":[\"这引出了另一种方法：\",[\"$\",\"strong\",null,{\"children\":\"纵向扩展\"}],\"或\",[\"$\",\"strong\",null,{\"children\":\"垂直扩展\"}],\"。\"]}],[\"$\",\"p\",null,{\"children\":\"纵向扩展意味着增加每个节点的计算能力，而不是增加更多节点。\"}],[\"$\",\"p\",null,{\"children\":\"每个叶交换机不直接连接到单个GPU，而是连接到包含多个GPU（比如每台服务器8个）的服务器。这减少了所需的直接网络交换机和线缆数量：\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"服务器节点内的8个GPU\",\"src\":\"https://substackcdn.com/image/fetch/$s_!VsZy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36ec7709-933b-4304-b57b-7fcd1962637d_1600x1007.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"每个服务器节点包含8个GPU；单个交换机可以管理更多GPU\"}]]}],[\"$\",\"p\",null,{\"children\":\"打个比方，在网络扩展的早期阶段，快速增长的公司可能首先通过增加CPU核心和内存来升级服务器。这是垂直扩展。当单个机器不够用时，他们会添加更多服务器和负载均衡器来分配流量。这是水平扩展。\"}],[\"$\",\"p\",null,{\"children\":[\"细心的观察者可能会想知道这些纵向扩展的GPU如何相互通信。\",[\"$\",\"em\",null,{\"children\":\"它们不是仍然需要通过网络交换机连接吗？如果是，这与横向扩展有何不同？\"}]]}],[\"$\",\"p\",null,{\"children\":\"非常好的观察！\"}],[\"$\",\"h3\",null,{\"className\":\"content-header\",\"id\":\"节点内通信与节点间通信\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#节点内通信与节点间通信\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],[\"$\",\"strong\",null,{\"children\":\"节点内通信与节点间通信\"}]]}],[\"$\",\"p\",null,{\"children\":[\"服务器节点内的通信称为\",[\"$\",\"strong\",null,{\"children\":\"节点内(intra-node)通信\"}],\"。\"]}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"节点内通信\",\"src\":\"https://substackcdn.com/image/fetch/$s_!ITIG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79d6dc18-85df-4d66-9c87-4ab246048464_2264x1290.png\"}]}],[\"$\",\"p\",null,{\"children\":[\"不同服务器节点上GPU之间的通信称为\",[\"$\",\"strong\",null,{\"children\":\"节点间(inter-node)通信\"}],\"。\"]}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"节点间通信\",\"src\":\"https://substackcdn.com/image/fetch/$s_!9dMC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5ea7fed-3ee1-47e0-b59c-bba369c86a78_1846x1750.png\"}]}],[\"$\",\"p\",null,{\"children\":\"事实证明，相邻节点内的GPU可以比使用节点间InfiniBand或以太网技术更快、更高带宽地通信。\"}],[\"$\",\"p\",null,{\"children\":\"为什么？\"}],[\"$\",\"p\",null,{\"children\":\"这主要是由于GPU的物理接近性和采用的专用互连技术。这些技术使用直接、短距离且优化的信号线路，通常直接集成在同一电路板上或共享封装内。这减少了信号传输距离并最小化了延迟。\"}],[\"$\",\"p\",null,{\"children\":\"例如，这是2018年IEEE国际固态电路会议(ISSCC)论文集中分享的AMD Infinity Fabric路由示意图：\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"AMD Infinity Fabric路由\",\"src\":\"https://substackcdn.com/image/fetch/$s_!Ax4m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feff05bd8-b3c9-48c1-b00f-054f6e16a7b0_1336x1496.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"亮色连接线(traces)代表计算单元之间的金属连接。可以将其视为封装基板中的\\\"线路\\\"。\"}]]}],[\"$\",\"p\",null,{\"children\":\"由于服务器内的GPU直接连接，它们可以避免节点间GPU服务器通信相关的大部分开销。封装内路由通过保持短线距、减少传播延迟和最小化信号衰减来提高效率。\"}],[\"$\",\"p\",null,{\"children\":\"InfiniBand和以太网等外部连接通常需要额外的信号完整性组件——如中继器、重定时器和纠错机制——以保持较长距离的可靠传输。这些可能会引入增量延迟并增加功耗。\"}],[\"$\",\"p\",null,{\"children\":\"我喜欢将节点内通信（如NVLink和InfinityFabric）比作德国高速公路(Autobahn)：设计为无中断高速行驶。\"}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"节点间通信则像双车道公路\"}],\"：速度较慢，容量有限，而且在春季播种或秋季收获期间可能需要减速绕过拖拉机（即处理拥堵）。\"]}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"小心前方可能有警车\",\"src\":\"https://substackcdn.com/image/fetch/$s_!SE5R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a3b38ac-9513-4c4a-92c0-e8c8f26d5865_660x440.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"小心，前面可能有警车！\"}]]}],[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"训练过程中的通信\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#训练过程中的通信\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],[\"$\",\"strong\",null,{\"children\":\"训练过程中的通信\"}]]}],[\"$\",\"p\",null,{\"children\":\"了解神经网络的训练方式有助于理解通信挑战。\"}],[\"$\",\"p\",null,{\"children\":[\"在每个训练周期中，网络首先执行\",[\"$\",\"strong\",null,{\"children\":\"前向传播\"}],\"，输入数据流经网络各层产生预测结果。然后通过损失函数将这一预测与正确答案进行比较，量化预测的偏差程度。\"]}],[\"$\",\"p\",null,{\"children\":[\"学习的核心发生在\",[\"$\",\"strong\",null,{\"children\":\"反向传播\"}],\"过程中，一种叫做反向传播的算法计算网络中每个权重对误差的贡献程度。利用这些信息，梯度下降算法调整所有权重朝着减少误差的方向——本质上是调整数十亿个\\\"旋钮\\\"，逐步提高网络的准确性。通过每次迭代，这些渐进式调整使神经网络能够在新数据上做出更可靠的预测。\"]}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"img\",null,{\"alt\":\"前向传播过程\",\"src\":\"https://substackcdn.com/image/fetch/$s_!c9W3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaf353e5-204b-4d51-b09a-ed8bdf2889fa_850x437.png\"}],\" \",[\"$\",\"em\",null,{\"children\":\"神经网络前向传播过程\"}]]}],[\"$\",\"p\",null,{\"children\":[\"每个GPU基于前向传播的误差计算权重更新的梯度，但由于每个GPU在不同的数据子集上工作，这些梯度只是部分结果。为确保所有GPU应用相同的更新并保持同步，\",[\"$\",\"strong\",null,{\"children\":\"需要在GPU间聚合和平均梯度\"}],\"。\"]}],[\"$\",\"p\",null,{\"children\":[\"这个过程，被称为\",[\"$\",\"strong\",null,{\"children\":\"all-reduce通信\"}],\"，允许GPU交换和分发最终计算值，然后更新它们的本地模型。通过维持全局一致性，这防止了模型偏移并确保有效的分布式训练。\"]}],[\"$\",\"p\",null,{\"children\":\"all-reduce通信的延迟直接影响训练效率。\"}],[\"$\",\"p\",null,{\"children\":\"英伟达的NCCL软件库还支持其他集体操作，例如：AllReduce、Broadcast、Reduce、AllGather和ReduceScatter。\"}],[\"$\",\"p\",null,{\"children\":\"正如我们在DeepSeek V3中看到的，有软件方法可以重叠通信和计算，减少GPU空闲时间，降低通信约束的影响。\"}],[\"$\",\"h2\",null,{\"className\":\"content-header\",\"id\":\"结论\",\"children\":[[\"$\",\"a\",null,{\"href\":\"#结论\",\"aria-hidden\":\"true\",\"tabIndex\":\"-1\",\"children\":[\"$\",\"span\",null,{\"className\":\"content-header-link\",\"children\":[\"$\",\"svg\",null,{\"className\":\"h-5 linkicon w-5\",\"fill\":\"currentColor\",\"viewBox\":\"0 0 20 20\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"children\":[[\"$\",\"path\",null,{\"d\":\"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z\"}],[\"$\",\"path\",null,{\"d\":\"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z\"}]]}]}]}],[\"$\",\"strong\",null,{\"children\":\"结论\"}]]}],[\"$\",\"p\",null,{\"children\":\"这是第一部分的全部内容。正如承诺的，内容非常温和！\"}],[\"$\",\"p\",null,{\"children\":\"还有很多内容需要讨论。实际的大规模集群并不是全网状的；情况更复杂。\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"复杂集群拓扑\",\"src\":\"https://substackcdn.com/image/fetch/$s_!lhOI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4548e3b-e518-4a5e-bbc2-cccf1c7d1db6_2580x1530.png\"}]}],[\"$\",\"p\",null,{\"children\":\"但希望你已经掌握了足够的知识，当看到图表和文档时，例如这张英伟达SuperPOD计算架构图，能够获得高层次的理解并提出问题以填补知识空白：\"}],[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"alt\":\"英伟达SuperPOD架构\",\"src\":\"https://substackcdn.com/image/fetch/$s_!H_OC!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6841c1fa-0603-4714-b4f7-b674960270b3_1386x1600.png\"}]}],[\"$\",\"p\",null,{\"children\":\"在上图中，我们可以看到脊交换机和叶交换机如何帮助横向扩展，以及B200服务器如何实现纵向扩展。\"}],[\"$\",\"p\",null,{\"children\":\"从表格中可以看出，每个可扩展单元(SU)有32个节点，每个节点有8个GPU。所以这是横向扩展（32个节点）和纵向扩展（每节点8个GPU）的结合。忽略\\\"移除一个DGX以容纳UFM连接\\\"的细节；重点是你现在可以大致理解这些内容了！\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"pb-6 pt-6 text-center text-gray-700 dark:text-gray-300\",\"id\":\"comment\",\"children\":[\"$\",\"$L19\",null,{\"slug\":\"ai/gpu-networking-basics\"}]}],[\"$\",\"footer\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col text-sm font-medium sm:flex-row sm:justify-between sm:text-base\",\"children\":[[\"$\",\"div\",null,{\"className\":\"pt-4 xl:pt-8\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/blog/go/go-memory-alignment-and-allocation\",\"className\":\"text-primary-500 hover:text-primary-600 dark:hover:text-primary-400\",\"aria-label\":\"Previous post: 深入理解 Go 的内存对齐与分配机制\",\"children\":[\"← \",\"深入理解 Go 的内存对齐与分配机制\"]}]}],[\"$\",\"div\",null,{\"className\":\"pt-4 xl:pt-8\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/blog/system/fair-queueing\",\"className\":\"text-primary-500 hover:text-primary-600 dark:hover:text-primary-400\",\"aria-label\":\"Next post: 使用公平队列防止多租户服务中的吵闹邻居问题\",\"children\":[\"使用公平队列防止多租户服务中的吵闹邻居问题\",\" →\"]}]}]]}]}]]}]]}]}]]}]]\n"])</script><script>self.__next_f.push([1,"15:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"GPU网络通信基础\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。\"}],[\"$\",\"meta\",\"4\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"5\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"6\",{\"rel\":\"canonical\",\"href\":\"https://blog.mainjay.cloudns.ch/blog/ai/gpu-networking-basics\"}],[\"$\",\"link\",\"7\",{\"rel\":\"alternate\",\"type\":\"application/rss+xml\",\"href\":\"https://blog.mainjay.cloudns.ch/feed.xml\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:title\",\"content\":\"GPU网络通信基础\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:description\",\"content\":\"深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:url\",\"content\":\"https://blog.mainjay.cloudns.ch/blog/ai/gpu-networking-basics\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:site_name\",\"content\":\"MainJayLai Blog\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:image\",\"content\":\"https://pngimg.com/uploads/github/github_PNG80.png\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"15\",{\"property\":\"article:published_time\",\"content\":\"2025-09-05T00:00:00.000Z\"}],[\"$\",\"meta\",\"16\",{\"property\":\"article:modified_time\",\"content\":\"2025-09-05T00:00:00.000Z\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:author\",\"content\":\"mainJayLai\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"GPU网络通信基础\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"深入解析大规模AI训练中的GPU网络通信原理、架构设计与优化策略，包括Scale Out/Up方案、层次化交换机拓扑以及通信模式。\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:image\",\"content\":\"https://pngimg.com/uploads/github/github_PNG80.png\"}],[\"$\",\"meta\",\"22\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"6:null\n"])</script></body></html>